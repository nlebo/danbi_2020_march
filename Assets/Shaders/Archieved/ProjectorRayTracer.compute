//#pragma kernel CSMain
//#include "Assets/Includes/DanbiRT.cginc"
////
//// Variables
////
//Texture2D<float4> _ProjectorTexture;
//SamplerState sampler_ProjectorTexture;
//float2 _quadUV;
//
////
//// UAV
////
//StructuredBuffer<MeshObject> _MeshObjects;
//StructuredBuffer<float3> _Vertices;
//StructuredBuffer<int> _Indices;
//StructuredBuffer<float2> _UVs;
//StructuredBuffer<float3> _Normals;
//
//StructuredBuffer<MeshObject> _ProjMeshObjects;
//StructuredBuffer<float3> _ProjVertices;
//StructuredBuffer<int> _ProjIndices;
//StructuredBuffer<float2> _ProjUVs;
//
//RWStructuredBuffer<float2> _Dbg_QuadUVs;
//
////
//// Entry points
//// Each thread group has a 8*8*1 array of threads
//// There're total 8 * 8 threads.
////
//// id : The index indicating the arbitrary thread.
//[numthreads(8, 8, 1)]
//void CSMain(uint3 id : SV_DispatchThreadID) {
//
//  //see https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-generating-camera-rays/generating-camera-rays?url=3d-basic-rendering/ray-tracing-generating-camera-rays/generating-camera-rays
//  // for the theory of ray tracing
//  uint width = 0, height = 0;
//  _Result.GetDimensions(width, height);
//
//  float aspectRatio = width / height; // assumes that width > height
//  // tan (theta) <half of the height>
//  float scale = tan(_FOV / 2);
//
//  // PixelOffset is added to draw each pixels randomly (not in order).
//  float2 uv = (float2)0;
//  uv.x = ((id.x + _PixelOffset.x) / width * 2.0f - 1.0f) * scale * aspectRatio;
//  uv.y = ((id.y + _PixelOffset.y) / height * 2.0f - 1.0f) * scale;
//
//  // Get a ray for the UVs.
//  Ray ray = CreateRayFromCamera(uv);
//  RayHit quadHit = CreateRayHit();
//  IntersectProjectorQuadMesh(ray, quadHit, _ProjMeshObjects[0]);
//  // Trace and shade.
//  float3 res = (float3)0;
//  for (int i = 0; i < _MaxBounceCount; ++i) {
//    RayHit hit = Trace(ray);
//    res += ray.energy * Shade(ray, hit);
//    // any() : True if any components of the x parameter are non-zero; otherwise, false.
//    if (!any(ray.energy))
//      break;
//  }
//  //res = mul(_DisplayCameraTRS, float4(res, 0)).xyz;
//  _Result[id.xy] = float4(res, 1.0);
//}
//
//void IntersectProjectorQuadMesh(Ray ray, inout RayHit bestHit, MeshObject mesh) {
//  uint count = mesh.indicesCount;
//  for (uint i = 0; i < count; i += 3) {
//    float3x3 vtx = float3x3(mul(mesh.localToWorldMatrix, float4(_ProjVertices[_ProjIndices[i]], 1)).xyz,
//                            mul(mesh.localToWorldMatrix, float4(_ProjVertices[_ProjIndices[i + 1]], 1)).xyz,
//                            mul(mesh.localToWorldMatrix, float4(_ProjVertices[_ProjIndices[i + 2]], 1)).xyz);
//    // retrieve uv.
//    float3x2 vtxUVs = float3x2(_ProjUVs[_ProjIndices[i]],
//                               _ProjUVs[_ProjIndices[i + 1]],
//                               _ProjUVs[_ProjIndices[i + 2]]);
//    //_dbg_vtxUVs[i] = vtxUVs;
//    float3 tuv = (float3)0;
//    if (IntersectTriangle_internal(ray, vtx, tuv, mesh.colorMode)) {
//      if (tuv[0] > 0.0 && tuv[0] < bestHit.distance) {
//        float2 quadUV = (1 - tuv[1] - tuv[2]) * vtxUVs[0]
//          + tuv[1] * vtxUVs[1]
//          + tuv[2] * vtxUVs[2];
//        //_Dbg_QuadUVs[0] = finalUV;
//        _quadUV = quadUV;
//        //bestHit.emission = _ProjectorTexture.SampleLevel(sampler_ProjectorTexture, finalUV, 0).xyz;
//      } // if-within distance
//    } // if-check the intersection
//  } // for  
//}
//
////Added by Moon
//void IntersectMesh(Ray ray, inout RayHit bestHit, MeshObject mesh) {
//  uint offset = mesh.indicesStride;
//  uint count = mesh.indicesCount + offset;
//
//  // check intersection of the current ray with all triangles in the current mesh
//  for (uint i = offset; i < count; i += 3) {
//    // retrieve vertex and transform local space to the world space.
//    float3x3 vtx = float3x3(mul(mesh.localToWorldMatrix, float4(_Vertices[_Indices[i]], 1)).xyz,
//                            mul(mesh.localToWorldMatrix, float4(_Vertices[_Indices[i + 1]], 1)).xyz,
//                            mul(mesh.localToWorldMatrix, float4(_Vertices[_Indices[i + 2]], 1)).xyz);
//    // retrieve uv.
//    float3x2 vtxUVs = float3x2(_UVs[_Indices[i]],
//                               _UVs[_Indices[i + 1]],
//                               _UVs[_Indices[i + 2]]);
//    // result of ray tracing.
//    // t : distance between the origin of the ray and the hit point.
//    // u, v : the hit point in the barycentric coordinates.
//    float3 tuv = (float3)0;
//    // Check the ray is intersected with the vertex.
//    if (IntersectTriangle_internal(ray, vtx, tuv, mesh.colorMode)) {
//      // if the length of ray to the hit point is nonzero and less than the currently min distance
//      if (tuv[0] > 0.0 && tuv[0] < bestHit.distance) {
//        bestHit.distance = tuv[0];
//        bestHit.position = ray.origin + tuv[0] * ray.direction;
//        bestHit.normal = normalize(cross(vtx[1] - vtx[0], vtx[2] - vtx[0]));
//        bestHit.albedo = (float3)0;
//        bestHit.specular = 0.5;
//
//        switch (mesh.colorMode) {
//          // Nothing to do (No Colors).
//          case 0:
//          bestHit.emission = (float3) 0.03;
//          break;
//
//          // Texture colors.
//          case 1:
//          // <see href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-to-samplelevel">HERE</href>
//          // SampleLevel -> is similar to Sample except that is uses the LOD level (in the last component of the location parameter) 
//          // to choose the mipmap level. For example, a 2D texture uses the first two components for uv coordinates and the third
//          // component for the mipmap level.        
//
//          // Conversion from the barycentric coordinates to the cartesian cooridnates - Added by Moon
//          /*float2 finalUV = (1 - tuv[1] - tuv[2]) * vtxUVs[0]
//            + tuv[1] * vtxUVs[1]
//            + tuv[2] * vtxUVs[2];*/
//            //bestHit.emission = float3(1, 0, 0);          
//          //bestHit.emission = _ProjectorTexture.SampleLevel(sampler_ProjectorTexture, _quadUV, 0).xyz;
//          bestHit.emission = float3(1, 0, 0);
//          break;
//        }
//      }
//    }/* else {
//      bestHit.emission = (float3)0;
//    }*/
//  } // for   
//}//IntersectMesh
//
//RayHit Trace(Ray ray) {
//  // Create RayHit.
//  RayHit bestHit = CreateRayHit();
//  // FinalUV is filled out here.
//  // check if the current ray hits the projector mesh.  
//
//  //IntersectProjectorMesh(ray, bestHit, _ProjMeshObjects[0], 0);
//  // Get Dimensions from MeshObjectsBuffer.
//  uint count = 0, stride = 0;
//  _MeshObjects.GetDimensions(count, stride);
//  // Iterate for ray tracing!
//  for (uint i = 0; i < count; ++i) {
//    IntersectMesh(ray, bestHit, _MeshObjects[i]);
//  }
//  return bestHit;
//}
//
//float3 Shade(inout Ray ray, RayHit hit) {
//  // Less than Infinity!
//  if (hit.distance < 1.#INF) {
//    // Reflect the ray and multiply energy with specular reflection.
//    ray.origin = hit.position + hit.normal * 0.001;
//    ray.direction = reflect(ray.direction, hit.normal);
//    ray.energy *= hit.specular;
//    return hit.emission;
//  } else {
//    // Erase the ray's energy - the sky doesn't reflect anything.
//    ray.energy = (float3)0.0;    
//
//    // 1. draw with constant Black color.
//    return (float3)0.1;
//
//    // 2. sample the skybox and write it.
//    /*float theta = acos(ray.direction.y) / -PI;
//    float phi = atan2(ray.direction.x, -ray.direction.z) / PI * 0.5;
//    return _SkyboxTexture.SampleLevel(sampler_SkyboxTexture, float2(phi, theta), 0).xyz;*/
//  }
//}
